---
title: '[KT Aivle 3기 AI] 12주차. 미니프로젝트 6차'
author: JIHWAN PARK
categories:
  - AI & 데이터분석
  - AIVLE SCHOOL
tag:
  - AIVLE SCHOOL
  - Deep Learning
  - Project
math: true
date: 2023-04-18 15:29:02 +0900
last_modified_at: 2023-04-20 14:26:22 +0900
published: true
image: "https://github.com/Jihwan98/Jihwan98.github.io/assets/76936390/6be11e55-36a3-4a86-8e30-d8928f732a0c"
---
> KT Aivle School 3기 AI 12주차. 미니프로젝트 6차
> - 53 ~ 54일차 (월 ~ 화)
>   - 강사 : 지병규 강사님
>   - 주제 : AIVLE School FAQ ChatBot 만들기
> - 55 ~ 56일차 (수 ~ 목)
>   - 강사 : 이호준 강사님
>   - 주제 : 장애인 이동권 개선을 위한 장애인 콜택시 대기시간 예측
{: .prompt-info}

# 🌟 12주차

12주차에는 월~화는 **AIVLE School FAQ ChatBot 만들기**라는 주제로 프로젝트를 진행했고, 수~목은 **장애인 이동권 개선을 위한 장애인 콜택시 대기시간 예측**을 주제로 프로젝트를 진행했다. 금요일에는 **AICE Associate 시험** 과 **1차 AIVLE DAY**가 예정되어 있었다. 금요일의 AICE 시험 때문인지, 이전의 미니프로젝트에 비해서는 상당히 쉽고 간단한 프로세스로 미니프로젝트가 진행되었다.

## 💡 미니프로젝트 6차 (1) (53일 ~ 54일차)
- 강사 : 지병규 강사님
- 주제 : AIVLE School FAQ ChatBot 만들기
- 데이터 : AIVLE School 홈페이지 Q&A 기반 자체 제작
- 코드 : [미니프로젝트 6차 (1) 코드 !](https://github.com/Jihwan98/aivle_school/tree/main/2023.04.17_%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%206%EC%B0%A8_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C)

해당 프로젝트는 앞서 미니프로젝트 4차에서 진행한 것과 프로세스가 거의 동일했다. 자연어 처리 쪽의 복습을 위해 해당 주제로 미니프로젝트를 선정하셨다고 하셨다! 따라서 앞서 진행한 기억이 있어 여유롭게 프로젝트를 진행할 수 있었다. ~~하지만 여전히 자연어 처리는 어려워..~~

데이터는 FAQ 데이터와 일상적인 질문에 대한 답변을 하기위해(좀 더 친숙한 느낌을 주는 ChatBot을 만들기 위해) 일상 질문 답변 데이터를 사용했다. 데이터는 질문과 답변 그리고 해당 질문이 어느 범주에 속하는지에 대한 intent가 있었다. 여기서 모델링을 수월하게 하기위해 일상 질문과 FAQ 데이터를 구분하는 type을 추가했다.

### ✅ 전처리
앞선 미니프로젝트와 마찬가지로 데이터에 대한 분석을 진행하고(단변량 분석, 이변량 분석 등. ex) 글자 길이, 질문 개수, 질문 별 길이와 개수 등등) 전처리를 진행했다. 전처리에는 크게 5가지 방법으로 진행했다. 특수문자 제거와 mecab을 통해 형태소 분석을 통해 Tokenize 하는 것은 공통적으로 진행하고, 1) Word2Vector를 scratch부터 학습시켜 진행 2) Tensorflow의 Tokenize를 활용하여 진행(띄어쓰기 기준으로 Tokenize할 것이므로 형태소 분석을 통한 Tokenize) 3) Pretrained된 Word2Vector를 사용하여 진행 4) Pretrained된 FastText를 사용하여 진행 5) KLUE를 사용하기위해 transformers libary의 AutoTokenizer 이용 의 방법으로 진행했다.

### ✅ 모델링
모델링은 intent를 바로 구분하는 방법과 일상 질문과 FAQ를 먼저 구분하고 질문의 Cosine Similarity를 이용해 가장 유사한 intent를 구하는 방법으로 진행했다.

기본적인 방법으로 진행했을 때는 일상 질문과 FAQ를 구분하는 것에 대해서는 거의 완벽하게 수행을 했지만, intent를 구분하는 것에 대해서는 intent의 수가 엄청나게 많아서 그런지 결과는 좋지 않았다. 답변은 `np.random.choice`를 이용해 예측한 intent의 train data의 답변들의 빈도에 맞춰 나오도록 했다. 

![image](https://user-images.githubusercontent.com/76936390/232997187-306d520c-8875-458b-bf6a-614ebce9a31e.png)
_ChatBot 1, 2, 3 답변 결과 (1)_

![image](https://user-images.githubusercontent.com/76936390/232998462-3dbeac6c-351b-4827-a81e-2631adf35886.png)
_ChatBot 1, 2, 3 답변 결과 (2)_

- 챗봇 1 : Word2Vec from scratch + LGBM (바로 intent 구분)
- 챗봇 2 : Pretrained Word2Vec + LGBM (type 구분) + Cosine Similarity
- 챗봇 3 : LSTM을 통한 type 구분 + FastText Cosine Similarity

**✔️ KLUE**

[KLUE 모델링 한 코드](https://github.com/Jihwan98/aivle_school/blob/main/2023.04.17_%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%206%EC%B0%A8_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%8D%B8%EB%A7%81_KLUE.ipynb), [KLUE 모델링 시 참고한 코드](https://www.notion.so/2023-04-17-18-53-54-12-6-1-4fa2f2d13d4d421eb822f2a03316ccd0?pvs=4#0c7dc0580f3f4aafad2d495d64de2794)

KLUE를 사용했을 때는, test intent에 대한 Accuracy가 92.5% 정도로 대폭 증가했다.(앞선 모델링에선 30%, 70% 정도 나왔다.) 기본 코드에서 크게 건든 것 없이 `klue/roberta-large` 모델을 가져와 사용하고 학습시켰을 때의 결과이다.

![image](https://user-images.githubusercontent.com/76936390/233000557-061b8a0e-a664-420a-a664-caf7acd78973.png)
_KLUE 모델 ChatBot 답변 결과 (1)_

![image](https://user-images.githubusercontent.com/76936390/233000650-9b5ec830-fb65-4849-9369-527218682a43.png)
_KLUE 모델 ChatBot 답변 결과 (2)_

![image](https://user-images.githubusercontent.com/76936390/233000743-c9d680ba-2f43-4df1-b200-160996eead93.png)
_KLUE 모델 ChatBot 답변 결과 (3)_

### ✅ 느낀점
이번에 제작해본 ChatBot 모델은 Generative한 모델이 아니어서 기존에 있는 답변만 진행할 수 있고, 사람이 미리 분류해놓은 범주에 맞춰 답변을 하기 때문에 해당 범주를 구분을 정확히 하지 못하면 엉뚱한 답변을 하고, 다소 어색하고 형식적인 답변들만 나오게 된다. 따라서 이번 프로젝트에서는 이 범주를 구분하는 것이 가장 중요했는데, 어쨌든 자연어 처리 쪽에서는 이미 엄청나게 많은 데이터로 미리 학습된 모델을 가져왔을 때 좋은 결과를 얻을 수 있었다.

하지만, 어떤식으로 전처리가 되고(Tokenize, 형태소 분석, Word Embedding, Subword Tokenize 등등..) 모델링이 되는지를 이해해야 해당 모델을 사용하고 활용할 수 있으며, 또 어떤 식으로 변화를 주어 성능을 올릴 수 있을 지를 알 수 있기 때문에, 막 가져다 써서 성능이 잘나왔더라만 중요한 것이 아니라 어떠한 과정을 통해 해당 결과가 나왔는지를 이해할 수 있어야 한다!

사실 미니프로젝트를 진행하다 보면 뭔가 방법을 탐구하기엔 시간도 부족하고, 또 Competition을 진행할 때는 결국 Score가 잘 나오는게 중요하다보니 이론적인 부분에서는 놓치는 부분이 있는 것 같다. 지금처럼 조금 여유로운 프로젝트를 진행할 때는, 이론적인 부분을 스스로 공부하면서 채워나가야겠다!!




## 💡 미니프로젝트 6차 (2) (55일 ~ 56일차)
- 강사 : 이호준 강사님
- 주제 : 장애인 이동권 개선을 위한 장애인 콜택시 대기시간 예측
- 데이터 : 장애인 콜택시 운행정보, 날씨 정보
- 코드 : [미니프로젝트 6차 (2) 코드 !](https://github.com/Jihwan98/aivle_school/tree/main/2023.04.19_%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%206%EC%B0%A8_3_4%EC%9D%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C)

해당 프로젝트는 강사님의 배려로 미니프로젝트의 분량을 줄여서 AICE 개인 공부를 할 수 있는 시간이 많았다.

데이터는 시계열 Tabular 데이터이며 장애인 콜택시의 도착 예정시간을 예측하는 모델을 개발하는 것이 목표였다.

장애인 콜택시의 서비스 불만 사항 중 1) 너무 긴 대기시간(71.3%)과 2) 일정하지 않은 대기시간(10%)이 1, 2위로 많은 부분을 차지하고 있다. 따라서 콜택시 도착 예정시간을 구해 사용자의 만족도를 올리자는 목표가 된다. 

### ✅ 전처리

해당 주제는 시계열 데이터로 당일 운행이 끝났을 때, 다음날의 평균 대기시간을 예측하는 것으로 Shift를 통해 Target에 대한 데이터를 생성해주었다. 그리고 날씨 데이터를 다음날의 예보 데이터로 사용하기 위해 마찬가지로 날짜를 하루씩 당겨 콜택시 운행정보 데이터와 merge 해주는 작업을 거쳤다. 그리고 공휴일, 최근 7일간의 평균 대기시간, 탑승율, 요일별, 일별, 주말 등등 다양한 새로운 feature들을 생성해서 넣어 주었다. 그리고 역시 다른 프로젝트와 마찬가지로 데이터에 대한 단변량, 다변량 분석을 진행했다. 

통계량을 보기위해 수치형 데이터는 상관계수를 확인해보았고, 범주형 데이터는 t-test(범주 2개)와 ANOVA(분산분석, 범주 3개 이상)을 진행하고 시각화해보았다. 수치형 데이터에서는 최근 7일간의 평균 대기시간, 전날의 평균 대기시간, 탑승률, 접수 건수, 탑승 건수 등이 어느정도 높은 상관계수를 보여주었고, 생각보다 날씨에 대한 데이터에서는 상관계수가 낮게 나왔다. 상관계수가 높은 데이터들에 대해서는 `sns.pairplot`(scatterplot)을 진행해보았다.

범주형 데이터에 대해서는 평균 비교 시각화(`sns.barplot`)를 진행하고, t-test와 ANOVA를 진행해서 범주간의 차이가 얼마나 있는지 확인해보았다. 

![image](https://user-images.githubusercontent.com/76936390/233263833-b8bb98d6-d438-4e18-aa14-b1bfb90e86bc.png)
_수치형 데이터의 상관계수 heatmap 시각화_

![image](https://user-images.githubusercontent.com/76936390/233264249-ec57258c-9008-442a-910f-7356cc5b6911.png)
_범주형 데이터의 평균 비교 시각화(`sns.barplot`)_

![image](https://user-images.githubusercontent.com/76936390/233264671-4d6a4327-52d7-4174-b6bf-0c9351ecfc86.png)
_범주형 데이터 t-test와 ANOVA 결과_


마지막으로 상관관계가 거의 없는 변수들은 제거를 하고 가변수화와 train, val, test 분리 후 Scaling을 진행하여 전처리를 마무리했다.

### ✅ 모델링

머신러닝 모델으로는 `LinearRegression`, `LGBMRegressor`, `SVM`을 사용해보았고, 이 중에서는 `SVM`이 가장 성능이 좋게 나왔다.

![image](https://user-images.githubusercontent.com/76936390/233265529-1196f6d9-8599-4f1f-97dd-10ac4642d1bf.png)
_SVM 모델 Validation과 Test 데이터에 대한 MAE, MAPE 결과_

![image](https://user-images.githubusercontent.com/76936390/233265534-cf3fd582-287b-4f86-8461-4ca1ed9b5710.png)
_실제 값과 SVM 모델의 Test 데이터에 대한 예측 값 시각화_


딥러닝 모델으로는 단순하게 Dense와 BatchNormalization, Dropout 등만 활용하여 모델링해보았는데, 단순하게 쌓을 수록 조금 더 좋은 성능을 보여주었다.

```
# 딥러닝 모델

Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 28)]              0         
                                                                 
 dense (Dense)               (None, 128)               3712      
                                                                 
 dense_1 (Dense)             (None, 64)                8256      
                                                                 
 dense_2 (Dense)             (None, 1)                 65        
                                                                 
=================================================================
Total params: 12,033
Trainable params: 12,033
Non-trainable params: 0
_________________________________________________________________
```
```
# Test Data에 대한 결과

===================Test===================
MAE : 4.617992074148995
MAPE : 0.11612565406671532
```

![image](https://user-images.githubusercontent.com/76936390/233266001-76cf4040-9722-4ce6-b996-a0c6a35e6d01.png)
_실제 값과 딥러닝 모델의 Test 데이터에 대한 예측 값 시각화_
