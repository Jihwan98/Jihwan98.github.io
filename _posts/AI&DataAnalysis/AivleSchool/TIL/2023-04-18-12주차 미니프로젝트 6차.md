---
title: '[KT Aivle 3기 AI] 12주차. 미니프로젝트 6차'
author: JIHWAN PARK
categories:
  - AI & 데이터분석
  - AIVLE SCHOOL
tag:
  - AIVLE SCHOOL
  - Deep Learning
  - Project
math: true
date: 2023-04-18 15:29:02 +0900
last_modified_at: 2023-04-18 15:29:02 +0900
published: true
---
> KT Aivle School 3기 AI 12주차. 미니프로젝트 6차
> - 53 ~ 54일차 (월 ~ 화)
>   - 강사 : 지병규 강사님
>   - 주제 : AIVLE School FAQ ChatBot 만들기
> - 55 ~ 56일차 (수 ~ 목)
>   - 강사 : 이호준 강사님
>   - 주제 : 장애인 이동권 개선을 위한 장애인 콜택시 대기시간 예측
{: .prompt-info}

# 🌟 12주차

12주차에는 월~화는 **AIVLE School FAQ ChatBot 만들기**라는 주제로 프로젝트를 진행했고, 수~목은 **장애인 이동권 개선을 위한 장애인 콜택시 대기시간 예측**을 주제로 프로젝트를 진행했다. 금요일에는 **AICE Associate 시험** 과 **1차 AIVLE DAY**가 예정되어 있었다. 금요일의 AICE 시험 때문인지, 이전의 미니프로젝트에 비해서는 상당히 쉽고 간단한 프로세스로 미니프로젝트가 진행되었다.

## 💡 미니프로젝트 6차 (1) (53일 ~ 54일차)
- 강사 : 지병규 강사님
- 주제 : AIVLE School FAQ ChatBot 만들기
- 데이터 : AIVLE School 홈페이지 Q&A 기반 자체 제작
- 코드 : [미니프로젝트 6차 (1) 코드 !](https://github.com/Jihwan98/aivle_school/tree/main/2023.04.17_%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%206%EC%B0%A8_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C)

해당 프로젝트는 앞서 미니프로젝트 4차에서 진행한 것과 프로세스가 거의 동일했다. 자연어 처리 쪽의 복습을 위해 해당 주제로 미니프로젝트를 선정하셨다고 하셨다! 따라서 앞서 진행한 기억이 있어 여유롭게 프로젝트를 진행할 수 있었다. ~~하지만 여전히 자연어 처리는 어려워..~~

데이터는 FAQ 데이터와 일상적인 질문에 대한 답변을 하기위해(좀 더 친숙한 느낌을 주는 ChatBot을 만들기 위해) 일상 질문 답변 데이터를 사용했다. 데이터는 질문과 답변 그리고 해당 질문이 어느 범주에 속하는지에 대한 intent가 있었다. 여기서 모델링을 수월하게 하기위해 일상 질문과 FAQ 데이터를 구분하는 type을 추가했다.

### ✅ 전처리
앞선 미니프로젝트와 마찬가지로 데이터에 대한 분석을 진행하고(단변량 분석, 이변량 분석 등. ex) 글자 길이, 질문 개수, 질문 별 길이와 개수 등등) 전처리를 진행했다. 전처리에는 크게 5가지 방법으로 진행했다. 특수문자 제거와 mecab을 통해 형태소 분석을 통해 Tokenize 하는 것은 공통적으로 진행하고, 1) Word2Vector를 scratch부터 학습시켜 진행 2) Tensorflow의 Tokenize를 활용하여 진행(띄어쓰기 기준으로 Tokenize할 것이므로 형태소 분석을 통한 Tokenize) 3) Pretrained된 Word2Vector를 사용하여 진행 4) Pretrained된 FastText를 사용하여 진행 5) KLUE를 사용하기위해 transformers libary의 AutoTokenizer 이용 의 방법으로 진행했다.

### ✅ 모델링
모델링은 intent를 바로 구분하는 방법과 일상 질문과 FAQ를 먼저 구분하고 질문의 Cosine Similarity를 이용해 가장 유사한 intent를 구하는 방법으로 진행했다.

기본적인 방법으로 진행했을 때는 일상 질문과 FAQ를 구분하는 것에 대해서는 거의 완벽하게 수행을 했지만, intent를 구분하는 것에 대해서는 intent의 수가 엄청나게 많아서 그런지 결과는 좋지 않았다. 답변은 `np.random.choice`를 이용해 예측한 intent의 train data의 답변들의 빈도에 맞춰 나오도록 했다. 

![image](https://user-images.githubusercontent.com/76936390/232997187-306d520c-8875-458b-bf6a-614ebce9a31e.png)
_ChatBot 1, 2, 3 답변 결과 (1)_

![image](https://user-images.githubusercontent.com/76936390/232998462-3dbeac6c-351b-4827-a81e-2631adf35886.png)
_ChatBot 1, 2, 3 답변 결과 (2)_

- 챗봇 1 : Word2Vec from scratch + LGBM (바로 intent 구분)
- 챗봇 2 : Pretrained Word2Vec + LGBM (type 구분) + Cosine Similarity
- 챗봇 3 : LSTM을 통한 type 구분 + FastText Cosine Similarity

**✔️ KLUE**

[KLUE 모델링 한 코드](https://github.com/Jihwan98/aivle_school/blob/main/2023.04.17_%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%206%EC%B0%A8_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%8D%B8%EB%A7%81_KLUE.ipynb), [KLUE 모델링 시 참고한 코드](https://www.notion.so/2023-04-17-18-53-54-12-6-1-4fa2f2d13d4d421eb822f2a03316ccd0?pvs=4#0c7dc0580f3f4aafad2d495d64de2794)

KLUE를 사용했을 때는, test intent에 대한 Accuracy가 92.5% 정도로 대폭 증가했다.(앞선 모델링에선 30%, 70% 정도 나왔다.) 기본 코드에서 크게 건든 것 없이 `klue/roberta-large` 모델을 가져와 사용하고 학습시켰을 때의 결과이다.

![image](https://user-images.githubusercontent.com/76936390/233000557-061b8a0e-a664-420a-a664-caf7acd78973.png)
_KLUE 모델 ChatBot 답변 결과 (1)_

![image](https://user-images.githubusercontent.com/76936390/233000650-9b5ec830-fb65-4849-9369-527218682a43.png)
_KLUE 모델 ChatBot 답변 결과 (2)_

![image](https://user-images.githubusercontent.com/76936390/233000743-c9d680ba-2f43-4df1-b200-160996eead93.png)
_KLUE 모델 ChatBot 답변 결과 (3)_

### ✅ 느낀점
이번에 제작해본 ChatBot 모델은 Generative한 모델이 아니어서 기존에 있는 답변만 진행할 수 있고, 사람이 미리 분류해놓은 범주에 맞춰 답변을 하기 때문에 해당 범주를 구분을 정확히 하지 못하면 엉뚱한 답변을 하고, 다소 어색하고 형식적인 답변들만 나오게 된다. 따라서 이번 프로젝트에서는 이 범주를 구분하는 것이 가장 중요했는데, 어쨌든 자연어 처리 쪽에서는 이미 엄청나게 많은 데이터로 미리 학습된 모델을 가져왔을 때 좋은 결과를 얻을 수 있었다.

하지만, 어떤식으로 전처리가 되고(Tokenize, 형태소 분석, Word Embedding, Subword Tokenize 등등..) 모델링이 되는지를 이해해야 해당 모델을 사용하고 활용할 수 있으며, 또 어떤 식으로 변화를 주어 성능을 올릴 수 있을 지를 알 수 있기 때문에, 막 가져다 써서 성능이 잘나왔더라만 중요한 것이 아니라 어떠한 과정을 통해 해당 결과가 나왔는지를 이해할 수 있어야 한다!

사실 미니프로젝트를 진행하다 보면 뭔가 방법을 탐구하기엔 시간도 부족하고, 또 Competition을 진행할 때는 결국 Score가 잘 나오는게 중요하다보니 이론적인 부분에서는 놓치는 부분이 있는 것 같다. 지금처럼 조금 여유로운 프로젝트를 진행할 때는, 이론적인 부분을 스스로 공부하면서 채워나가야겠다!!