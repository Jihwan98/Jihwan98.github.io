---
title: '[KT Aivle 3기 AI] 10주차. 미니프로젝트 4차'
author: JIHWAN PARK
categories:
  - AI & 데이터분석
  - AIVLE SCHOOL
tag:
  - AIVLE SCHOOL
  - Deep Learning
  - Project
math: true
date: '2023-04-07 17:11:59 +0900'
last_modified_at: '2023-04-07 17:11:59 +0900'
published: true
---
> KT Aivle School 3기 AI 10주차. 미니프로젝트 4차
> - 강사 : 지병규 강사님
> - 주제 : AIVLE-EDU 의 1:1 문의 내용 기반 문의 유형 자동 분류기
{: .prompt-info}

# 🌟 10주차

<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.04.03_%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B84%EC%B0%A8_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C' target='_blank'>[미니프로젝트 4차 코드!]</a>

10주차는 일주일동안 4차 미니프로젝트가 진행되었다. AIVLE-EDU 의 1:1 문의 내용 기반 문의 유형 자동 분류기를 만드는 것이 주제였다. 해당 데이터를 전처리하는 것 부터 모델링까지 진행했다.

## ✅ 데이터 분석 및 전처리

먼저, 나는 자연어 처리에 대한 경험이 없어서 처음엔 되게 막막했었다. 하지만 강사님 가이드라인을 따라가면서 모르는 부분은 구글링을 해보면서 개념을 서서히 익혀갈 수 있었다. 그래서 Tokenize 하는 다양한 방법들도 알게 되었고, 한국어의 경우 영어와 다르게 형태소 분석이라든지 다양한 방법들이 존재하는 것을 확인할 수 있었다.

어쨌든, 데이터에 대한 기본적인 분석을 진행했고, 이후 머신러닝과 딥러닝 모델링을 진행했다.

먼저 데이터에서 가장 눈에 띄는 특징은 Class Imbanace였다.(label 별 개수가 차이가 많이 나는 것이었다.) 그래서 이를 해결하기위해 oversampling 기법 중 하나인 SMOTE를 사용해서 진행해보았다. 그리고, 텍스트의 길이가 대부분 일정 범위 안에 있고 엄청나게 긴 텍스트 들이 있었는데, 엄청나게 긴 텍스트의 경우 오류나 자신의 코드를 그대로 복붙한 경우가 많았다. 그리고 다양한 형태소 분석기(Kkma, Okt, Komoran, Mecab 등)를 사용해 형태소 분석을 진행해보았고 실행시간도 체크해봤는데, Mecab이 가장 빨라서 Mecab으로 쭉 진행했다. 분석된 내용을 바탕으로 각 class별 단어들의 빈도수도 확인해보고 워드클라우드도 만들어보았다. 

특수 문자와 불용어도 제거 해보고, 품사 태깅에서 NNG(일반 명사)와 NNP(고유 명사), 외국어(SL)만 사용도 해보고, word2vec도 사용해보고, N-Gram도 해보고 정말 다양한 방법으로 전처리를 시도해보았다. 그리고 딥러닝 모델이 영어에서 성능이 좋기 때문에(언어 분절이 쉬워서) 영어로 번역도 해서 진행해보았다.

진짜 정말 다양한 방법들로 머신러닝 모델과 딥러닝 모델에 학습을 시켜보았다.

## ✅ 머신러닝

머신러닝에서는 다른 조 분들은 Auto ML을 많이 사용해보신 듯 했다. 그중에서는 Ridge Classifier가 가장 좋게 나오는 듯 했다. 우리 조는 Logistic Regression, SVM, Random Forest, Xgboost, LightGBM, Catboost 등을 사용해 보았고, 다양한 전처리 방법들에 대해서 대개 Logistic Regression이 가장 좋은 성능을 보였다. 그 중에서 BoerderlineSMOTE를 통해 over sampling을 하고 Gride Search를 통해 하이퍼파라미터 튜닝을 진행한 결과 Logistic Regression이 Kaggle Dataset에서 0.86정도의 macro F1-Score를 기록했다.

## ✅ 딥러닝

딥러닝에서는 from scratch로 했을 때는 머신러닝보다 좋지 않은 성능을 보여서 pretrained 모델을 사용하는 것으로 진행했다. (근데 4등한 조는 1D-CNN으로 해당 성능을 내셨다고 한다 ㄷㄷ 대단하다.) 그 중 우리는 KoBERT와 KcELECTRA 를 위주로 사용했고, 마찬가지로 영어로 번역한 것에 대해서 BERT와 ELECTRA를 사용해보았다. 해당 모델들을 사용했을 때 과적합이 빨리 일어나는 것 같아서, early stopping도 주고 dropout 층도 추가해주고, pretrained model 부분은 freeze 해보고, 일부만 freeze 해보고, LayerNorm 도 추가해보고, pretrained model의 LayerNorm은 모두 학습시켜 보고 정말 다양한 방법을 진행해보았지만, 눈에띄게 성능이 좋아지는 경우는 없었다. 그리고 maxlen도 조절해가면서도 해보았는데, 큰 차이는 없었다.

그러다가 우리조 한 분이 KcELECTRA를 그냥 epoch 100번을 학습시켰는데 결국엔 이 모델의 성능이 가장 좋았다. KoELECTRA도 동일하게 해보았는데, 역시 학습 데이터의 특징상 KcELECTRA가 더 좋은 성능을 보여주었다.

> - KcELECTRA는 댓글, 대댓글 등의 데이터로 학습함
> - 💡 NOTE 💡 
>   -  General Corpus로 학습한 KoELECTRA가 보편적인 task에서는 성능이 더 잘 나올 가능성이 높습니다. KcBERT/KcELECTRA는 User genrated, Noisy text에 대해서 보다 잘 동작하는 PLM입니다.
>       - KcELECTRA Github 발췌

## ✅ 결과

![image](https://user-images.githubusercontent.com/76936390/230573222-b7d9e30a-5f77-408c-9716-fd3271e6f4d8.png)
_Kaggle Competition 결과_

우리는 Kaggle Competition에서 macro F1-Score가 0.88408으로 전체 5등을 달성했다!👏

결과적으로 우리가 진행했던 모든 다양한 방법들에서 좋은 성능이 나오지 않았고, AutoTokenizer를 활용해서 전처리를 진행하고 많은 데이터로 잘 pretrained 된 모델을 가져오는 것이 좋은 성능이 나왔다. 

추가적으로 우리 데이터가 부족했기 때문에, Augmentation을 해보았으면 더 좋지 않았을까 하는 아쉬움이 있다.

그리고 1등, 2등 조는 KLUE-BERT 모델을 사용했는데, 우리는 KLUE-BERT 모델을 사용해보지도 못해서 너무 아쉬웠고, 1D-CNN으로도 저렇게 좋은 성능을 내는 조가 정말 대단하다고 생각이 들었다.

정말 아직 많이 부족한 것 같고, 우리조도 발표 했지만, 다른 조들의 발표를 보면서 많이 배울 수 있었고 우리 조원 분들한테도 많은 것을 배울 수 있어서 좋은 프로젝트였다!!!

점점 더 쌓은 지식들이 정리되고 앞으로도 많이 지식을 쌓아서 능력있는 좋은 개발자가 되고 싶다!!
