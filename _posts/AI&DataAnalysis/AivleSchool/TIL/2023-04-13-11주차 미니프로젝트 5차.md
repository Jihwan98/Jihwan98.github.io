---
title: '[KT Aivle 3기 AI] 11주차. 미니프로젝트 5차'
author: JIHWAN PARK
categories:
  - AI & 데이터분석
  - AIVLE SCHOOL
tag:
  - AIVLE SCHOOL
  - Deep Learning
math: true
date: 2023-04-13 10:09:35 +0900
last_modified_at: 2023-04-14 19:17:07 +0900
published: true
---
> KT Aivle School 3기 AI 11주차. 미니프로젝트 5차
> - 강사 : 이호준 강사님
> - 주제 : 스마트폰 센서 기반 데이터를 활용한 행동 인식
{: .prompt-info}

# 🌟 11주차

<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.04.12_%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B85%EC%B0%A8_3_5%EC%9D%BC%EC%B0%A8%20%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C' target='_blank'>[미니프로젝트 5차 코드!]</a>

11주차에는 월~화는 AICE 시험 대비 프로젝트를 진행했고, 수~금은 **"스마트폰 센서 기반 데이터를 활용한 행동 인식"**을 주제로 5차 미니프로젝트를 진행했다.

## ✅ 5차 미니프로젝트

**"스마트폰 센서 기반 데이터를 활용한 행동 인식"**이 주제인 것 처럼, 역시 데이터는 스마트폰 센서 데이터였다. 총 561개의 Feature를 통해 6개의 Class를 구분하는 문제였다. 

이러한 것을 **인간 행동 인식(HAR : Human Activity Recognition)**이라 말하며, 다양한 센서를 활용하여 사람의 모션에 관련된 정보를 수집하고 해석하여 행동을 인식하는 기술이다. 이는 최근 스마트 워치에서 위험상황을 인지하여 SOS Call을 할 지 말지 하는 등의 서비스로 제공될 수 있다.

## ✅ 데이터

데이터는 [이 곳](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)의 데이터를 사용했다. 2012년에 Samsung Galaxy S 2를 허리에 차고 데이터를 수집했다고 한다.

스마트폰 센서에는 **가속도 센서(Accelerometer)**와 **자이로스코프 센서(Gyroscope)** 두 가지 센서가 있다고 한다.

가속도 센서(Accelerometer)
: 일직선으로 움직이는 물체의 _선형 가속도_를 측정하는 센서. <mark>"일정 시간 동안 X, Y, Z 축으로 얼마나 빠르게 움직였는가?"</mark>

자이로스코프 센서(Gyroscope)
: 회전하는 물체의 _각속도_를 측정하는 센서. <mark>"일정 시간 동안 X, Y, Z 축으로 각도가 얼마나 변했는가?"</mark>

이 센서들로 수집한 데이터를 2.56초 범위(Window), 1.28초 간격으로 이동하며 데이터 샘플링을 했다고 한다.(**하나의 행**)

그리고 하나의 Window에서 수집된 데이터를 신호별로 분리 후 집계 했다고 한다.

## ✅ 프로젝트 진행 방식

지금 데이터에는 상당히 많은 Feature를 가지고 있다.
- EDA 수행의 어려움 : 모든 Feature들에 대해서 다 그래프를 그려야 할까?
- 모델의 복잡도 증가 : 모든 Feature가 모델링에 필요할까?

⇒ 선택과 집중을 한다!
- 트리 기반 모델로 **변수 중요도를 추출**하여 상위 N개 변수에 대해 탐색 및 모델링

6개의 Class는 상호 관련이 있다.
- 정적 : Laying, Sitting, Standing
- 동적 : Walking, Walking-Up, Walking-Down

⇒ 단계별 모델링을 한다!
- 1단계 : 정적과 동적을 분류하는 모델
- 2단계 : 분류한 것을 세부 Class로 분류하는 모델


위와 같은 내용으로 프로젝트를 진행하도록 구성되어있었고, 이에 맞춰서 프로젝트를 진행했는데, 모델은 어떤 것을 써도 정확도가 거의 99%가 나올정도로 상당히 쉽게 분류했다. 이는 모델이 성능이 좋아야 해당 모델의 Feature Importance가 유의미하기 때문에, 강사님이 의도했다고 하셨다.

효율에 대한 탐구 → 실제 현업에서는 이것보다 훨씬 많은 Feature, Rows가 존재함. 따라서 특징들을 탐색해서 필요한 Feature들만 뽑아서 사용하는 작업이 필요할 수 있다. 


### ✔ 정적 동적 구분

먼저 정적과 동적을 구분하는 데에 있어서는 하위 Feature들은 Feature Importance가 거의 0에 가까운 것을 확인할 수 있었고, 상위 51개만 사용해보았다. 이렇게 진행했을 때 LinearDiscriminantAnalysis 모델으로 99.9%의 정확도를 보여주었다. 확실히 kde plot으로 확인해보았을 때, 뚜렷하게 구분되는 것을 확인할 수 있었는데, 결과로 나타났다.

![image](https://user-images.githubusercontent.com/76936390/231657464-11fc60f9-0f01-413f-8375-2b96265c13d5.png)
_정적과 동적을 구분하는 RandomForest Model 상위 51개의 Feature Importance_

![image](https://user-images.githubusercontent.com/76936390/231658678-cc37ee80-d2f8-4136-827c-2e25cfc03daa.png)
_정적과 동적을 구분하는 Feature Importance 상위 6개에 대한 kde plot_

### ✔ 정적 Class 구분

정적 Class를 구분할 때는, Feature를 줄이면 성능이 많이 떨어졌다. Feature Importance는 상위 N개가 상당히 높은 것을 볼 수 있었으나, 세부적으로 비슷한 것을 구분할 때는 하위 Feature들을 사용하는 듯 했다. kde plot으로 확인해보면, Laying의 경우는 확실히 다른 분포를 보여주나, Standing과 Sitting은 어느정도 비슷한 분포를 보여주는 듯 했다. LogisticRegression을 사용했을 때, 상위 50개를 사용할 때는 94%대의 정확도를, 상위 100개를 사용할 때는 95%의 정확도를 보여주었다.

![image](https://user-images.githubusercontent.com/76936390/231661892-a51ff08d-6589-4be4-80f2-130010c8f0f1.png)
_정적 Class를 구분하는 RandomForest Model 상위 100개의 Feature Importance_

![image](https://user-images.githubusercontent.com/76936390/231661957-7369d3d0-1d54-4b26-9ee2-6ad519011d1a.png)
_정적 Class를 구분하는 Feature Importance 상위 6개에 대한 kde plot_

### ✔ 동적 Class 구분
동적 Class는 생각보다 성능이 많이 떨어지지 않았는데, kde plot으로 확인해봤을 때 3개가 각각 모두 구분되지는 않지만 어떤 Feature에서는 두 가지로 구분이되고 또 다른 Feature에서는 또 다른 두 부분으로 구분이되는 듯해보였다. 그래서 정적 Class와는 달리 Feature를 줄였을 때 성능이 많이 줄어들지 않은 듯 했다. LinearDiscriminantAnalysis 모델을 사용하고 상위 100개를 사용했을 때, 98% 대의 정확도를 보여주었다.

![image](https://user-images.githubusercontent.com/76936390/231662916-002e0b99-d50d-4efe-a928-257acd715c30.png)
_동적 Class를 구분하는 RandomForest Model 상위 100개의 Feature Importance_

![image](https://user-images.githubusercontent.com/76936390/231662984-7652ad7b-7517-4196-be60-4ec5e6c9170a.png)
_동적 Class를 구분하는 Feature Importance 상위 6개에 대한 kde plot_

### ✔ Auto ML

Auto ML도 사용해봤는데, 생각보다 시간이 너무 오래걸려서 전체 Feature를 다 넣었을 때, 6개의 Class 구분과 동적/정적 구분에 대한 부분만 돌려보았다. 금요일 Kaggle Competition을 할 때 다시 시도해봐야겠다. 

Auto ML으로는 [PyCaret](https://pycaret.gitbook.io/docs/)과 [mljar](https://github.com/mljar/mljar-supervised)을 사용해보았다. 특히 mljar는 너무 오래 걸려서 6개의 Class 구분하는데에만 사용해보았다.

**PyCaret**

6개의 Class를 구분하는 것의 결과는 LGBM이 가장 좋은 결과가 나왔다.

![image](https://user-images.githubusercontent.com/76936390/231664200-996dc939-c91a-458f-975a-04fcaae704da.png)
_6개의 Class 구분 PyCaret 결과_

![image](https://user-images.githubusercontent.com/76936390/231664524-c66ec992-29a3-4ab5-a19d-a93b0a828fcc.png)
_best 모델의 Feature Importance_

동적/정적을 구분하는 것의 결과는 Ridge Classifier와 Linear Discriminant Analysis가 모두 맞춰버리는 결과를 보여주었다.

![image](https://user-images.githubusercontent.com/76936390/231664934-e01f612a-7fb2-4c78-9729-a839e96578ea.png)
_동적/정적 구분 PyCaret 결과_

![image](https://user-images.githubusercontent.com/76936390/231665170-4b1c09ac-7e0a-45be-9ae3-87876f051437.png)
_best 모델의 Feature Importance_


**mljar**

mljar는 local에 결과가 저장되는데, colab에서 돌리고 결과를 따로 저장하지 않아서 기록이 없다... 일단 Best Model은 Ensemble 모델으로 나왔는데, 내 기억엔 몇 가지 모델을 섞어서 Ensemble 한 것으로 기억한다. 해당 모델의 Validation Set에 대한 Accuracy는 99%가 나왔다.


## ✅ Feature를 없애보기

Feature Importance 상위 N개를 없애면서 몇개까지 없애도 성능이 잘 나오는지를 간단히 확인해봤다.

먼저 정적/동적 구분하는 Task에 있어서는 하위 2개의 Feature만 남겨도 정확도가 98%가 나올 정도로 잘 구분해내는 것을 확인할 수 있었다. 확실히 정적/동적인 Class의 차이는 상당히 뚜렷하다고 볼 수 있다.

정적 Class 구분은 애초에 하위 N개를 없앴을 때에도 성능이 많이 떨어졌기 때문에 마찬가지로 성능이 많이 떨어졌다.

동적 Class 구분은 상위 400개를 없앴을 때, 정확도가 96% 대가 나오는 것을 확인했다.

# ✅ Kaggle Competition

[[내가 작성한 코드들 ..]](https://github.com/Jihwan98/aivle_school/tree/main/2023.04.12_%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B85%EC%B0%A8_3_5%EC%9D%BC%EC%B0%A8%20%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C/Kaggle_Competition)

4/14(금)에는 개인별 Kaggle Competition을 진행했다. 주제는 마찬가지로 동일한 주제였으며, 데이터는 동일하지만 일부 특정 컬럼 50개만 있는 데이터였다. (강사님이 나중에 말씀해주셨지만, Feature Importance 하위 50개였다.) 

나는 다시 순차적으로 데이터를 확인하면서 진행했다.

나는 PyCaret을 통해서 모델 탐색을 해보고, Scaler를 적용했을 때와 안했을 때의 결과차이(사실 일부 컬럼은 min max 값이 -1과 1이 아니지만(결국 범위 안에 있음) 이미 모든 데이터가 -1 ~ 1의 범위로 값을 가지고 있어 의미가 크게 없었던 것 같음.)를 확인해보고, 다중 분류이기 때문에 Class Imbalance 문제를 확인해본 결과 분포 차이가 크게 나지는 않지만, 조금은 났기 때문에 SMOTE와 Borderline SMOTE도 진행해보았다. 그리고 [GAN for Tabular Data](https://github.com/Diyago/GAN-for-tabular-data)를 활용해서 Data Augmentation을 진행해보았다. 그리고 모델은 머신러닝 모델과 딥러닝 모두 해봤는데, 딥러닝 같은 경우에는 직접 쌓았을 경우 크게 좋지 않아서 검색해본결과 TabNet이라는 Tabular 데이터를 위한 딥러닝 모델이 있었는데 시간이 많지 않아서 직접 해보지는 못했다.

DataAugmentation을 진행했을 때, 조금의 성능 향상은 있었지만 큰 효과는 보지 못했다.

mljar의 AutoML도 시도해봤는데, parameter를 주는 방법을 몰라 그냥 기본대로만 진행하니 엄청 오래 걸려서 Augmentation한 데이터에는 사용해보지 못했지만 최종적으로 mljar의 결과로 나온 모델로 예측했을 때 가장 좋은 성능이 나왔다.

이어서 다른 분들의 발표를 들어보았는데, 전처리에 집중해서 해보신 분들도 있었고, 모델 하나만 잡고 Hyperparameter를 조절해가면서 최적의 성능을 뽑아 내신 분들도 있었다. 그리고 또 다른 AutoML을 사용해서 좋은 성능을 보여주신 분들도 있었다.

대부분 [아마존에서 만든 AutoML인 AugoGluon](https://auto.gluon.ai/stable/api/autogluon.tabular.models.html)을 많이 사용했고, 해당 AutoML에서 좋은 결과를 얻으셨다.

그리고 나도 확인할 수 있었지만 이번 Task에서는 LGBM이 가장 좋은 성능을 보여주어서, 다른 분들 중에 LGBM의 Hyperparameter에서 n_estimator, learning_rate, max_depth, num_leaves, max_bin 등등을 조절해서 성능을 올리신 분들도 많았다.

이번 프로젝으텡서는 생각보다는 전처리나 어떤 특별한 방법에 의해서 성능이 대폭 향상되었다기보다, Hyperparameter 조절 등의 요소에서 성능이 많이 좌우된 듯해서 AutoML이 가장 강력했던 것 같다.

나는 아쉽게도 상대적으로 그리 좋은 성적은 얻지못해 최상위권은 아니지만, 최종적으로 100점을 주는 커트라인에는 들었다.

이번 프로젝트에서도 역시 다른분들의 발표에서 많은 것을 배울 수 있었다.