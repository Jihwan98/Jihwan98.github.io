---
title:  "[KT Aivle 3기 AI] 7주차 (28~32일차). CNN(Convolutional Neural Network)"
author: JIHWAN PARK
categories: [AI & 데이터분석, AIVLE SCHOOL]
tag: [AIVLE SCHOOL, Machine Learning, Deep Learning, CNN]
math: true
date: 2023-03-13 18:00:00 +0900
last_modified_at: 2023-03-16 20:43:22 +0900
---
> KT Aivle School 3기 AI 28~29일차 
> - 강사 : 김건영 강사님
> - 주제 : CNN(Convolutional Neural Network)
> - 내용 :
>   - CNN에 대해서 배움
>   - stride, zero-padding, Max Pooling 등에 대해 배움
>   - Image Data Augmentation 에 대해서 배우고 실습
>   - Pretrained Model, Transfer Learning
>   - ModelCheckpoint, model.save()
>   - Object Detection, YOLO
{: .prompt-info}

## 💡 28일차. TIL
<details>
<summary>28일차(3/13)</summary>
<div markdown="1">
오늘은 CNN에 대해서 배웠다. 이미 학부때 배웠던 내용이라 다시 기억을 상기시키며 들었다. 

CNN이 나오게 된 계기 : 이미지의 위치정보를 없애지 않고 처리하기 위함

CNN 연산에는 kernel_size와 stride가 영향을 미치며, 기본적으로 사이즈가 작아지고 합성곱의 불균형이 생긴다.

CNN 연산 결과 크기 공식 : `output_size = (N - F) / stride + 1`

사이즈가 작아지고 합성곱의 불균형을 해결하기 위해 zero-padding이라는 기법이 생겼다.

그리고, 연산량을 줄이기 위해 Max Pooling이라는 기법이 생겼는데, Max Pooling은 filter_size에서 가장 큰 값을 가져오는 것이다.

~~`relu` 함수를 주로 쓰는 상황에서 Max Pooling이 가장 알맞다고 볼 수 있다?~~

그리고, Batch Normalization과 Dropout에 대해 간단하게 배우고 사용했는데, 둘 다 모델을 Robust하게 만들어주는 기능이다.

Batch Normalization은 mini batch를 정규화 시켜주고, Dropout은 지정한 비율로 랜덤하게 노드를 죽이게 되어 초기 weight 값에 덜 민감하게 만들어 준다.

y가 범주형인데 numerical으로 있는 경우 (ex: y = [1, 2, 3, 4, 5, ...]) 원래는 `to_categorical`으로 전처리를 해줘야 하지만,

전처리 없이 `loss = keras.losses.sparse_categorical_crossentropy`을 사용하면 학습 가능하다.


<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.03.13.CNN_2.0ver/1_My_First_CNN' target='_blank'>[CNN 관련 코드]</a>

CNN Modeling 예시 코드

```python
# 1. 세션 클리어
keras.backend.clear_session()

# 2. 모델 연결
il = Input(shape=(28, 28, 1))
cl = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(il)
bl = BatchNormalization()(cl)
cl = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(bl)
bl = BatchNormalization()(cl)
pl = MaxPool2D(pool_size=(2, 2))(bl)
dl = Dropout(0.25)(pl)

cl = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(il)
bl = BatchNormalization()(cl)
cl = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(bl)
bl = BatchNormalization()(cl)
pl = MaxPool2D(pool_size=(2, 2))(bl)
dl = Dropout(0.25)(pl)

fl = Flatten()(dl)
dl = Dense(512, activation='relu')(fl)
bl = BatchNormalization()(dl)
ol = Dense(10, activation='softmax')(bl)

model = keras.models.Model(il, ol)

# 3. 모델 컴파일
model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'], optimizer='adam')

# 4. 요약
model.summary()
```
</div>
</details>


## 💡 29일차. TIL
<details>
<summary>29일차(3/14)</summary>
<div markdown="1">
오늘은 어제에 이어 CNN 모델을 만들고 학습을 진행했다.

그리고 Image Data Augmentation에 대해 간략히 배우고 실습을 진행했다.

실제 현실에서는 충분한 Data가 있지 않으므로, 부족한 데이터를 채워주기 위해 기존의 데이터를 조금 변형 시켜 데이터를 늘리는 방법이 Data Augmentation이다.

이를 keras의 ImageDataGenerator를 통해 진행할 수 있다.

<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.03.13.CNN_2.0ver/2_Data_augmentation_and_more' target='_blank'>[Augmentaion 관련 코드]</a>

</div>
</details>

## 💡 30일차. TIL
<details>
<summary>30일차(3/15)</summary>
<div markdown="1">
- 모델을 저장하고 불러오는 방법을 배움(ModelCheckpoint, model.save())
- Transfer Learning : Pretrained Model을 가져와서 우리 문제에 맞게 구조를 살짝 바꿔 학습시킨다. ex) input ~ hidden layer 까지 Frozen (weight update x), output 직전 또는 output layer만 고쳐쓰기
- ReduceLROnPlateau : Learning Rate 조절하는 도구
- Global Average Pooling : Feature Map의 각 depth의 평균을 가져옴 -> 연산량 줄이기
- Object Detection 맛보기 : YOLO V3 가져와서 사용해보기
<details>
<summary>Object Detection</summary>
<div markdown="1">
- object detection = Classification + Localization = Multi-Labeled Classification + Bounding Box Regression
- 주요 학습 데이터
    - Pascal VOC Dataset
        - mAP(mean Average Precision) 등장
        - 2007년 2012년 데이터셋이 벤치마크 데이터셋으로 주로 쓰였음
        - 문제점
            - 이미지 안의 object가 크가
            - object가 이미지 중앙에 있다.
            - object의 종류가 적다(20개)
    - COCO Dataset
        - 기존 데이터셋에 대한 문제 제기
        - 현재 많이 쓰임
        - object 크기, 위치가 다양함 (class 80개)
        - Non-iconic 이미지(정확히 어떤 object를 가리키는지 모름)
        - mAP 사용, IoU를 0.50 ~ 0.95 유동적 적용
- 크게 one-stage, two-stage detector 가 있음
- object localization하고 classification을 하는지, 같이하는 지
- one - Yolo, two - fast RCNN

- Yolo(You Only Look Once)
    - One stage detector
    - UltraLytics라는 회사에서 개발
</div>
</details>
<br>
<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.03.13.CNN_2.0ver/2_Data_augmentation_and_more' target='_blank'>[Pretrained, Trnasfer Learning 관련 코드]</a>

<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.03.15.Object_Detection' target='_blank'>[Object Detection 관련 코드]</a>

</div>
</details>

## 💡 31일차. TIL

<details>
<summary>31일차(3/16) Object Detection 정리!🌟</summary>
<div markdown="1">

<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.03.15.Object_Detection' target='_blank'>[Object Detection 관련 코드]</a>

## ✅ Object Detection
Object Detection = Classification + Localization = Multi-Labeled Classification + Bounding Box Regression

### ✔️ Bounding Box
하나의 Object가 들어있는 최소 크기의 박스. 구성요소로는 위치 정보(x, y, w, h)가 있음. 결국 이 위치정보를 Regression 학습하게 된다. 그리고 이 박스로 IoU(Intersection over Union)를 계산한다. IoU 값은 0 ~ 1의 값이며 높을 수록 많이 겹치는 것이다.

### ✔️ Class Classification
Bounding Box에 있는 Object를 Class Classification 한다.

### ✔️ Confidence Score
Bounding Box에 물체가 있을 확률. 모델 마다 다르지만 YOLO에서는 Bounding Box에 물체가 있을 확률 x Class 확률이다.

### ✔️ CNN이 Object Detection에서 하는 역할
**Back Bone**으로 쓰임. CNN구조가 위치 정보 Feature를 잘 가져올 거라는 기대를 한 것(ImageNet을 통해 잘 학습된 모델을 가져다 쓰면 안될까?) - VGG, Inception, ResNet 등등 ..

> **Head** : 우리 문제에 맞게 변형하는 부분 (뒷단 부분)<br>
> **Neck** : Back Bone과 Head를 연결하는 부분
{: .prompt-tip}

### ✔️ 주요 학습 데이터
**Pascal VOC Dataset**

- mAP(mean Average Precision) 등장
- 총 20개의 class
- 2007년 2012년 데이터셋이 벤치마크 데이터셋으로 주로 쓰였음

**COCO Dataset✨**

- 기존 데이터셋(Pascal VOC)에 대한 문제 제기
    - 이미지 안의 object가 크다.
    - object가 이미지 중앙에 있다.
    - object의 종류가 적다(20개)
- 현재 많이 쓰이는 데이터셋
- object의 크기, 위치가 다양하고 80개의 class가 있음
- Non-iconic 이미지가 존재(정확히 어떤 object를 가리키는지 모름)
- mAP 사용, IoU를 0.50 ~ 0.95 유동적 적용

---

YOLO 실습을 진행했다. 생각보다 Object Detect가 잘되어서 놀랬다. Object Detection 부분은 처음해봐서 재밌기도 했고 신기했다. 그 원리가 너무 궁금해서 이해하기 위해서 혼자 이것저것 찾아보는 중이다.

> `NMS(Non Maximum Suppression)`와 `Anchor Box` 개념 이해하기
{: .prompt-tip}

</div>
</details>