---
title:  "[KT Aivle 3기 AI] 28일차. CNN(Convolutional Neural Network)"
author: JIHWAN PARK
categories: [AI & 데이터분석, AIVLE SCHOOL]
tag: [AIVLE SCHOOL, Machine Learning, Deep Learning, CNN]
math: true
date: 2023-03-13 18:00:00 +0900
last_modified_at: 2023-03-13 18:00:00 +0900
---
> KT Aivle School 3기 AI 28일차 
> - 강사 : 김건영 강사님
> - 주제 : CNN
> - 내용 :
>   - CNN에 대해서 배움
>   - stride, zero-padding, Max Pooling 등에 대해 배움
>   - 코드로 구현
{: .prompt-info}

## 💡 28일차. TIL
오늘은 CNN에 대해서 배웠다. 이미 학부때 배웠던 내용이라 다시 기억을 상기시키며 들었다. 

CNN이 나오게 된 계기 : 이미지의 위치정보를 없애지 않고 처리하기 위함

CNN 연산에는 kernel_size와 stride가 영향을 미치며, 기본적으로 사이즈가 작아지고 합성곱의 불균형이 생긴다.

CNN 연산 결과 크기 공식 : `output_size = (N - F) / stride + 1`

사이즈가 작아지고 합성곱의 불균형을 해결하기 위해 zero-padding이라는 기법이 생겼다.

그리고, 연산량을 줄이기 위해 Max Pooling이라는 기법이 생겼는데, Max Pooling은 filter_size에서 가장 큰 값을 가져오는 것이다.

~~`relu` 함수를 주로 쓰는 상황에서 Max Pooling이 가장 알맞다고 볼 수 있다?~~

그리고, Batch Normalization과 Dropout에 대해 간단하게 배우고 사용했는데, 둘 다 모델을 Robust하게 만들어주는 기능이다.

Batch Normalization은 mini batch를 정규화 시켜주고, Dropout은 지정한 비율로 랜덤하게 노드를 죽이게 되어 초기 weight 값에 덜 민감하게 만들어 준다.

y가 범주형인데 numerical으로 있는 경우 (ex: y = [1, 2, 3, 4, 5, ...]) 원래는 `to_categorical`으로 전처리를 해줘야 하지만,

전처리 없이 `loss = keras.losses.sparse_categorical_crossentropy`을 사용하면 학습 가능하다.


<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.03.13.CNN_2.0ver/1_My_First_CNN' target='_blank'>[CNN 관련 코드]</a>