---
title:  "[KT Aivle 3ê¸° AI] 28ì¼ì°¨. CNN(Convolutional Neural Network)"
author: JIHWAN PARK
categories: [AI & ë°ì´í„°ë¶„ì„, AIVLE SCHOOL]
tag: [AIVLE SCHOOL, Machine Learning, Deep Learning, CNN]
math: true
date: 2023-03-13 18:00:00 +0900
last_modified_at: 2023-03-13 23:00:00 +0900
---
> KT Aivle School 3ê¸° AI 28ì¼ì°¨ 
> - ê°•ì‚¬ : ê¹€ê±´ì˜ ê°•ì‚¬ë‹˜
> - ì£¼ì œ : CNN
> - ë‚´ìš© :
>   - CNNì— ëŒ€í•´ì„œ ë°°ì›€
>   - stride, zero-padding, Max Pooling ë“±ì— ëŒ€í•´ ë°°ì›€
>   - ì½”ë“œë¡œ êµ¬í˜„
{: .prompt-info}

## ğŸ’¡ 28ì¼ì°¨. TIL
ì˜¤ëŠ˜ì€ CNNì— ëŒ€í•´ì„œ ë°°ì› ë‹¤. ì´ë¯¸ í•™ë¶€ë•Œ ë°°ì› ë˜ ë‚´ìš©ì´ë¼ ë‹¤ì‹œ ê¸°ì–µì„ ìƒê¸°ì‹œí‚¤ë©° ë“¤ì—ˆë‹¤. 

CNNì´ ë‚˜ì˜¤ê²Œ ëœ ê³„ê¸° : ì´ë¯¸ì§€ì˜ ìœ„ì¹˜ì •ë³´ë¥¼ ì—†ì• ì§€ ì•Šê³  ì²˜ë¦¬í•˜ê¸° ìœ„í•¨

CNN ì—°ì‚°ì—ëŠ” kernel_sizeì™€ strideê°€ ì˜í–¥ì„ ë¯¸ì¹˜ë©°, ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ì´ì¦ˆê°€ ì‘ì•„ì§€ê³  í•©ì„±ê³±ì˜ ë¶ˆê· í˜•ì´ ìƒê¸´ë‹¤.

CNN ì—°ì‚° ê²°ê³¼ í¬ê¸° ê³µì‹ : `output_size = (N - F) / stride + 1`

ì‚¬ì´ì¦ˆê°€ ì‘ì•„ì§€ê³  í•©ì„±ê³±ì˜ ë¶ˆê· í˜•ì„ í•´ê²°í•˜ê¸° ìœ„í•´ zero-paddingì´ë¼ëŠ” ê¸°ë²•ì´ ìƒê²¼ë‹¤.

ê·¸ë¦¬ê³ , ì—°ì‚°ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ Max Poolingì´ë¼ëŠ” ê¸°ë²•ì´ ìƒê²¼ëŠ”ë°, Max Poolingì€ filter_sizeì—ì„œ ê°€ì¥ í° ê°’ì„ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ë‹¤.

~~`relu` í•¨ìˆ˜ë¥¼ ì£¼ë¡œ ì“°ëŠ” ìƒí™©ì—ì„œ Max Poolingì´ ê°€ì¥ ì•Œë§ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤?~~

ê·¸ë¦¬ê³ , Batch Normalizationê³¼ Dropoutì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ë°°ìš°ê³  ì‚¬ìš©í–ˆëŠ”ë°, ë‘˜ ë‹¤ ëª¨ë¸ì„ Robustí•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ê¸°ëŠ¥ì´ë‹¤.

Batch Normalizationì€ mini batchë¥¼ ì •ê·œí™” ì‹œì¼œì£¼ê³ , Dropoutì€ ì§€ì •í•œ ë¹„ìœ¨ë¡œ ëœë¤í•˜ê²Œ ë…¸ë“œë¥¼ ì£½ì´ê²Œ ë˜ì–´ ì´ˆê¸° weight ê°’ì— ëœ ë¯¼ê°í•˜ê²Œ ë§Œë“¤ì–´ ì¤€ë‹¤.

yê°€ ë²”ì£¼í˜•ì¸ë° numericalìœ¼ë¡œ ìˆëŠ” ê²½ìš° (ex: y = [1, 2, 3, 4, 5, ...]) ì›ë˜ëŠ” `to_categorical`ìœ¼ë¡œ ì „ì²˜ë¦¬ë¥¼ í•´ì¤˜ì•¼ í•˜ì§€ë§Œ,

ì „ì²˜ë¦¬ ì—†ì´ `loss = keras.losses.sparse_categorical_crossentropy`ì„ ì‚¬ìš©í•˜ë©´ í•™ìŠµ ê°€ëŠ¥í•˜ë‹¤.


<a href='https://github.com/Jihwan98/aivle_school/tree/main/2023.03.13.CNN_2.0ver/1_My_First_CNN' target='_blank'>[CNN ê´€ë ¨ ì½”ë“œ]</a>

CNN Modeling ì˜ˆì‹œ ì½”ë“œ

```python
# 1. ì„¸ì…˜ í´ë¦¬ì–´
keras.backend.clear_session()

# 2. ëª¨ë¸ ì—°ê²°
il = Input(shape=(28, 28, 1))
cl = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(il)
bl = BatchNormalization()(cl)
cl = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(bl)
bl = BatchNormalization()(cl)
pl = MaxPool2D(pool_size=(2, 2))(bl)
dl = Dropout(0.25)(pl)

cl = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(il)
bl = BatchNormalization()(cl)
cl = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(bl)
bl = BatchNormalization()(cl)
pl = MaxPool2D(pool_size=(2, 2))(bl)
dl = Dropout(0.25)(pl)

fl = Flatten()(dl)
dl = Dense(512, activation='relu')(fl)
bl = BatchNormalization()(dl)
ol = Dense(10, activation='softmax')(bl)

model = keras.models.Model(il, ol)

# 3. ëª¨ë¸ ì»´íŒŒì¼
model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'], optimizer='adam')

# 4. ìš”ì•½
model.summary()
```