---
title:  "[사전학습] 6.1 가설의 의의와 검정"
author: JIHWAN PARK
categories: [AI & 데이터분석, AIVLE SCHOOL]
tag: [사전학습, AIVLE SCHOOL, Python, Jupyter Notebook, Numpy, Pandas]
math: true
date: 2023-01-30 18:00:00 +0900
last_modified_at: 2023-01-30 18:00:00 +0900
---

# 가설의 의의와 검정
## 가설 검정이란?
**모집단**에 어떤 가설을 설정한 뒤, 통계 기법을 이용한 가설의 채택 여부를 확률적으로 판정하는 **통계적 추론**의 방법

|귀무가설|대립가설|
|---|---|
|비교하는 값과 차이가 **없다**|비교하는 값과 차이가 **있다**|
|기존 이론 가설|연구자 목적, 주장|
|$H_0$ : Null Hypothesis|$H_1$ or $H_\alpha$ : Alternative Hypothesis|

## 가설 검정 통계적 오류
**제1종 오류**와 **제2종 오류**가 존재

||귀무가설 : 진실|대립가설 : 진실|
|---|---|---|
|귀무가설 선택|옳은 결정<br>신뢰수준(1-$\alpha$)|**제2종 오류**<br>$\beta$|
|대립가설 선택|**제1종 오류**<br>유의수준($\alpha$)|옳은 결정<br>검정력(1-$\beta$)|

- 제 1종 오류 ($\alpha$) : $H_0$이 *참*이지만, $H_1$으로 **잘못 선택** -> "유의수준"이라고 불림
- 제 2종 오류 ($\beta$) : $H_1$이 *참*이지만, $H_0$으로 **잘못 선택**

## 가설 검정 방법
목적에 맞는 설정 필요
- 양측 검정<br>
    검정 통계량의 분포에서 기각영역이 **양쪽**에 나타나는 형태의 가설검정
    - 귀무가설 : $H_0$ : $\mu = \mu_0$
    - 대립가설 : $H_1$ : $\mu \neq \mu_0$

- 단측 검정<br>
    검정 통계량의 분포에서 기각 영역이 **한쪽**에 나타나는 형태의 가설검정
    - 귀무가설 : $H_0$ : $\mu = \mu_0$
    - 대립가설 : $H_1$ : $\mu < \mu_0$ 또는 $H_1$ : $\mu > \mu_0$

## 가설 기반 의사 결정 방법
**검정 통계량**과 **유의 확률**을 토대로 가설 채택 여부 결정
- 검정 통계량   >   기각역      ->  귀무가설 기각
- 검정 통계량   <   기각역      ->  귀무가설 채택
- 유의 확률     <   유의수준    ->  귀무가설 기각
- 유의 확률     >   유의수준    ->  귀무가설 채택

## 단일표본 t 검정
가장 기본적인 가설 검정 중 하나<br>
한 *모집단의 평균값*과 *기준값*의 *차이를 비교*하는 분석법

## 독립표본 t 검정
두 집단 간 평균의 차이를 비교하는 분석법<br>
[기본 가정]<br>
- 독립성 : 독립변수의 그룹군은 서로 독립
- 정규성 : 집단별 종속변수는 정규분포를 만족
- 등분산성 : 집단별 종속 변수 분포의 분산은 각 군마다 동일

## 기타 통계 분석 기법..
- ANOVA, 카이제곱, 상관분석 등

## 가설 검정 순서
1. 가설 수립
2. 판단 기준 수립
3. 통계 기법 도출
4. 분석 통계량 산출
5. 판단 기준
6. 결과 도출

# 실습
sample data 필요


```python
import numpy as np
import pandas as pd

from scipy import stats

import matplotlib.pyplot as plt
import seaborn as sns
```


```python
df = pd.read_csv('./data/interior_effect.csv')
display(df.head())
```


```python
# 데이터 셔플
df = df.sample(frac=1, random_state=0).reset_index(drop=True)
```


```python
df.shape
```

## boxplot


```python
p = sns.boxplot(x=df['interior'], y=df['preference'])
p.set_title('Box Plot of Preference of Interior')
```

## Assumption 1 : 독립성
> 독립변수 그룹은 서로 독립적<br>

두개의 집단을 구성하는 구성원이나 구성들이 서로 관계가 없음을 의미. 즉, 아무런 관계가 없어야함
## Assumption 2 : 정규성 확인
Shapiro-Wilk 검정을 통해 정규성을 확인합니다.<br>
귀무 가설과 대립 가설은 아래와 같습니다.
- $H_0$ : 각 독립 표본이 정규성을 만족한다.
- $H_1$ : 각 독립 표본이 정규성을 만족하지 않는다.


```python
df.loc[ df['interior'] == 'classic', 'interior'].value_counts()
```


```python
classic_pref = df.loc[ df['interior'] == 'classic', 'preference' ]

modern_pref = df.loc[ df['interior'] == 'modern', 'preference' ]
print(modern_pref)
```


```python
modern_pref.size
```


```python
# 정규성을 충족하는지 확인
print('classic 인테리어 선호도 정규성 shapiro test : ', stats.shapiro(classic_pref))
print('modern 인테리어 선호도 정규성 shapiro test : ', stats.shapiro(modern_pref))
```

## Assumption 3 : 등분산성 확인 (두 집단이 동일한 분산을 가지는가?)
F 검정으로 확인
- $H_0$ : 두 독립 표본의 분산은 동일하다.
- $H_1$ : 두 독립 표본의 분산은 동일하지 않다.


```python
f = np.var(classic_pref, ddof=1) / np.var(modern_pref, ddof=1)
classic_size = classic_pref.size - 1
modern_size = modern_pref.size - 1

p_value = 1 - stats.f.cdf(f, classic_size, modern_size)

print('F statistics : {}'.format(np.round(f, 4)))
print('p value : {:.3f}'.format(p_value, 4))
```


```python
def f_test(g1, g2):
    f = np.var(g1, ddof=1) / np.var(g2, ddof=1)
    num = g1.size - 1
    denom = g2.size - 1

    p_value = 1 - stats.f.cdf(f, num, denom)

    return f, p_value
```

## 독립표본 t 검정


```python
print(np.mean(classic_pref))
print(np.mean(modern_pref))
```


```python
result = stats.ttest_ind(classic_pref, modern_pref, equal_var=False)
```


```python
print('classic 인테리어 평균 선호도 : ', np.mean(classic_pref))
print('modern 인테리어 평균 선호도 : ', np.round(np.mean(modern_pref), 4))
print('독립표본 t 검정통계량 : ', result[0].astype(str)[:6])
print('p - value : ', result[1].astype(str)[:5])
```


```python

```
